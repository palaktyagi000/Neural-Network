{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_from_scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dIjUHmxGP2"
      },
      "source": [
        "### P.1 Intro and Neuron Code\n",
        "\n",
        "inputs = [1, 2, 3]\n",
        "weights = [0.2, 0.8, -0.5]\n",
        "bias = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "482OU5zVxkWw",
        "outputId": "d85c7e46-1eb3-4285-bf2a-4d2bd94ee437"
      },
      "source": [
        "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcmYUjncyCEO"
      },
      "source": [
        "### P.2 Coding a Layer\n",
        "\n",
        "inputs = [1, 2, 3, 2.5]\n",
        "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
        "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
        "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
        "bias1 = 2\n",
        "bias2 = 3\n",
        "bias3 = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaJwn-As0dwb",
        "outputId": "2a24bea2-9d93-439d-dc8c-f776b2d9d08c"
      },
      "source": [
        "output = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + inputs[3]*weights1[3] + bias1,\n",
        "          inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + inputs[3]*weights2[3] + bias2,\n",
        "          inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + inputs[3]*weights3[3] + bias3]\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8, 1.21, 2.385]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EszzhfaP03_-",
        "outputId": "bb0cd337-a95c-47bb-f2ce-2f7203f9ab88"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [0.2, 0.8, -0.5, 1.0]\n",
        "bias = 2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n,\\n           [0.5, -0.91, 0.26, -0.5],\\n           [-0.26, -0.27, 0.17, 0.87]]\\n\\nbiases = [2, 3, 0.5]\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnry50OomouK",
        "outputId": "3d51c2d9-cb51-4940-966c-7fea35fa3ab9"
      },
      "source": [
        "output = np.dot(inputs, weights) + bias\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "7k6WlXh65YjO",
        "outputId": "5fd49971-8bdb-49d8-9817-f88592be24a1"
      },
      "source": [
        "'''\n",
        "\n",
        "layer_outputs = [] #OUtput of current layer\n",
        "for neuron_weights, neuron_bias in zip(weights, biases):\n",
        "  neuron_output = 0 #OUtput of given neuron\n",
        "  for n_input, weight in zip(inputs, neuron_weights):\n",
        "    neuron_output += n_input*weight\n",
        "  neuron_output += neuron_bias\n",
        "  layer_outputs.append(neuron_output)\n",
        "\n",
        "print(layer_outputs)\n",
        "\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nlayer_outputs = [] #OUtput of current layer\\nfor neuron_weights, neuron_bias in zip(weights, biases):\\n  neuron_output = 0 #OUtput of given neuron\\n  for n_input, weight in zip(inputs, neuron_weights):\\n    neuron_output += n_input*weight\\n  neuron_output += neuron_bias\\n  layer_outputs.append(neuron_output)\\n\\nprint(layer_outputs)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozdv4vToronN",
        "outputId": "a2f6f008-2f29-41b4-bab5-632ce756a0ef"
      },
      "source": [
        "### P.3 The Dot Product\n",
        "import numpy as np \n",
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.5, -0.91, 0.26, -0.5],\n",
        "           [-0.26, -0.27, 0.17, 0.87]]\n",
        "bias = [2, 3, 0.5]\n",
        "output = np.dot(weights, inputs) + bias\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8   1.21  2.385]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu8kZKwhsSBP",
        "outputId": "ed1fc116-6137-4c71-8d19-e724860ed7aa"
      },
      "source": [
        "import numpy as np \n",
        "inputs = [[1, 2, 3, 2.5],\n",
        "          [2.0, 5.0, -1.0, 2.0],\n",
        "          [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "weights1 = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.5, -0.91, 0.26, -0.5],\n",
        "           [-0.26, -0.27, 0.17, 0.87]]\n",
        "biases = [2, 3, 0.5]\n",
        "\n",
        "weights2 = [[0.1, -0.14, 0.5],\n",
        "          [-0.5, 0.12, -0.33],\n",
        "           [-0.44, 0.73, -0.13]]\n",
        "biases2 = [-1, 2, -0.5]\n",
        "\n",
        "\n",
        "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
        "\n",
        "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
        "\n",
        "print(layer2_outputs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.5031  -1.04185 -2.03875]\n",
            " [ 0.2434  -2.7332  -5.7633 ]\n",
            " [-0.99314  1.41254 -0.35655]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPvGdAPTxCSa",
        "outputId": "b276dcfa-deb4-4ef5-b0a9-e996aa3f61f4"
      },
      "source": [
        "### P.4 Batches, Layers, and Objects\n",
        "\n",
        "\n",
        "X =  [[1, 2, 3, 2.5],\n",
        "      [2.0, 5.0, -1.0, 2.0],\n",
        "      [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "class Layer_Dense:\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "layer1 = Layer_Dense(4, 5)\n",
        "layer2 = Layer_Dense(5, 2)\n",
        "\n",
        "layer1.forward(X)\n",
        "print(layer1.output)\n",
        "\n",
        "layer2.forward(layer1.output)\n",
        "print(layer2.output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.49011403  0.24948581 -0.05915978 -0.05797267 -0.26936759]\n",
            " [ 0.10860546  0.9378391  -0.19180363 -0.16660229 -0.88848944]\n",
            " [ 0.58853626  0.31009468  0.22717629  0.38545678 -0.83981081]]\n",
            "[[-0.08669069 -0.01956471]\n",
            " [-0.0803777  -0.00088373]\n",
            " [-0.24255571 -0.03805494]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL1uAiy-2wtH",
        "outputId": "f7cf06e2-16a8-4539-c7e2-6a0f5eed8ff6"
      },
      "source": [
        "### P.5 Hidden Layer Activation Functions\n",
        "'''\n",
        "step function \n",
        "y = 1 if x>0\n",
        "y = 0 if x<=0\n",
        "\n",
        "Every neuron will have a activtaion function associated with it\n",
        "Generally the output neuron will have th different activation function not same as hidden layers.\n",
        "\n",
        "\n",
        "Ques- So a question arises why we use activation function at all?\n",
        "Ans- If we don't use the activation function then we will get the output which was our input.\n",
        "y = x\n",
        "it will give linear. And can only fit linear it will be hard to fit polynomial so that's where activation functions comes in the role.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "X =  [[1, 2, 3, 2.5],\n",
        "      [2.0, 5.0, -1.0, 2.0],\n",
        "      [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
        "output = []\n",
        "\n",
        "for i in inputs:\n",
        "  if i > 0:\n",
        "    output.append(i)\n",
        "  elif i <= 0:\n",
        "    output.append(0)\n",
        "\n",
        "print(output)\n",
        "          \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 2, 0, 3.3, 0, 1.1, 2.2, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs_EasJynkjr"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "#from nnfs.datasets import spiral_data\n",
        "##np.random.seed(0)\n",
        "#nnfs.init()\n",
        "\n",
        "X, y = spiral_data(100, 3)\n",
        "\n",
        "X =  [[1, 2, 3, 2.5],\n",
        "      [2.0, 5.0, -1.0, 2.0],\n",
        "      [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "class Layer_Dense:\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "class Activation_ReLU:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0, inputs)\n",
        "\n",
        "layer1 = Layer_Dense(4,5)\n",
        "activation1 = Activation_ReLU()\n",
        "  \n",
        "layer1.forward(X)\n",
        "print(layer1.output)\n",
        "activation1.forward(layer1.output)\n",
        "print(activation1.ouput)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ansjESxxoBoe"
      },
      "source": [
        "##!pip install nnfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjheFkf8ol1u"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "def create_data(points, classes):\n",
        "  X = np.zeros((points*classes, 2))\n",
        "  y = np.zeros(points*classes, dtype='uint8')\n",
        "  for class_number in range(classes):\n",
        "    ix = range(points*class_number, points*(class_number+1))\n",
        "    r = np.linspace(0.0, 1, points) #radius\n",
        "    t = np.linspace(class_number * 4, (class_number+1)*4, points) + np.randn(points)*0.2\n",
        "    X[ix] = np.c[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
        "    y[ix] = class_number\n",
        "  return X, y\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"here\")\n",
        "X, y = create_data(100, 3)\n",
        "\n",
        "plt.scatter(X[:,0], X[:])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMAgac6GtdOB",
        "outputId": "404731b0-d74b-450b-8333-24f0176d3737"
      },
      "source": [
        "### P.6 Softmax Activation \n",
        "import math\n",
        "layer_outputs = [4.8, 1.21, 2.385] \n",
        "#E = 2.1718\n",
        "E = math.e\n",
        "exp_values = []\n",
        "\n",
        "for output in layer_outputs:\n",
        "  exp_values.append(E**output)\n",
        "\n",
        "print(exp_values)\n",
        "\n",
        "norm_base = sum(exp_values)\n",
        "norm_values = []\n",
        "\n",
        "for value in exp_values:\n",
        "  norm_values.append(value / norm_base)\n",
        "\n",
        "print(norm_values)\n",
        "print(sum(norm_values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n",
            "[0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
            "0.9999999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjyDFLIUwwR8",
        "outputId": "8bc05ad0-6e73-4942-e267-c6ef520fe8ae"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "exp_values = np.exp(layer_outputs)\n",
        "\n",
        "norm_values = exp_values / np.sum(exp_values)\n",
        "\n",
        "print(norm_values)\n",
        "print(sum(norm_values))\n",
        "\n",
        "## softmax = exponential + Normalization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.89528266 0.02470831 0.08000903]\n",
            "0.9999999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cumzRa9YyZHg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}